# app.py - Ã‡OK DÄ°LLÄ° VE Ã‡OK KATMANLI KODLAMA ASÄ°STANI

import streamlit as st
from rag_pipeline import initialize_rag_system
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.chains import RetrievalQA

# --- A. SÄ°STEM BAÅžLATMA (CACHE) ---
@st.cache_resource
def setup_system():
    try:
        # rag_pipeline'dan vektÃ¶r depolarÄ±nÄ± ve LLM'i yÃ¼kler
        _, vector_stores, llm = initialize_rag_system()
        return vector_stores, llm
    except Exception as e:
        st.error(f"RAG Sistemi BaÅŸlatÄ±lamadÄ±! Detay: {e}")
        st.stop()

vector_stores, llm = setup_system()

# --- B. PROMPT ÅžABLONLARI ---

# 1. YÃ¶nlendirici (Router) Prompt'u: Sadece kategori adÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.
CLASSIFIER_PROMPT = """Analyze the user query and classify it into one of the following categories:
- 'kodlama_rehberi': If the query is about writing code, syntax, SQL, or programming help.
- 'hata_ayiklama_asistani': If the query is about specific errors, bugs, or troubleshooting.

Output ONLY the category name.

Query: {query}
Category:"""

# 2. Mentor (QA) Prompt'u: Bilgi veren ve dili otomatik ayarlayan prompt.
QA_PROMPT_TEMPLATE = """You are a highly skilled software mentor. 
Answer the user's question using ONLY the provided context.

1. Respond in the SAME language as the user's question (e.g., if Turkish -> answer Turkish, if Japanese -> answer Japanese).
2. If the context is in English and the question is in another language, translate and explain technically.
3. Provide code examples in clear code blocks.
4. If the answer is not in the context, say: "I don't have information on this in my database."

Context: {context}
Question: {query}
Answer:"""

QA_PROMPT = PromptTemplate(
    template=QA_PROMPT_TEMPLATE, 
    input_variables=["context", "query"]
)

# --- C. ZÄ°NCÄ°RLER VE MANTIK ---

# Sorgu sÄ±nÄ±flandÄ±rma zinciri
classifier_chain = (
    PromptTemplate.from_template(CLASSIFIER_PROMPT)
    | llm
    | StrOutputParser()
)

def get_response(query: str):
    # 1. AdÄ±m: Sorgunun hangi kategoriye ait olduÄŸunu bul
    topic = classifier_chain.invoke({"query": query}).strip().lower()

    if topic in vector_stores:
        st.info(f"YÃ¶nlendirilen Bilgi AlanÄ±: **{topic.upper()}**")
        retriever = vector_stores[topic].as_retriever(search_kwargs={"k": 5})

        # 2. AdÄ±m: SeÃ§ilen alana Ã¶zel RAG zincirini kur (Ã–zel QA_PROMPT ile)
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": QA_PROMPT} # KeyError'Ä± ve dili Ã§Ã¶zen yer
        )

        # 3. AdÄ±m: CevabÄ± Ãœret
        result = qa_chain.invoke({"query": query})
        return result['result'], result['source_documents']
    else:
        return f"Sorgunuz sÄ±nÄ±flandÄ±rÄ±lamadÄ±. Konu: {topic}", []

# --- D. ARAYÃœZ (UI) AYARLARI ---

LANG_OPTIONS = {
    'TR': {
        'title': "ðŸ¤– Ã‡ok Dilli Kodlama AsistanÄ±",
        'intro': "Merhaba! Hangi teknik konuda yardÄ±mcÄ± olabilirim?",
        'input_hint': "SQL JOIN hatasÄ± veya Python metodlarÄ± hakkÄ±nda sorun...",
        'expander': "ðŸ“š KaynaklarÄ± GÃ¶r",
        'spinner': "Cevap sentezleniyor..."
    },
    'EN': {
        'title': "ðŸ¤– Multilingual Coding Assistant",
        'intro': "Hello! How can I assist you with a technical problem?",
        'input_hint': "Ask about SQL JOIN errors or Python methods...",
        'expander': "ðŸ“š View Sources",
        'spinner': "Synthesizing answer..."
    }
}

if 'lang' not in st.session_state: st.session_state.lang = 'TR'

st.set_page_config(page_title="GenAI Coding Assistant", layout="wide")

# Dil SeÃ§imi (Toggle)
if st.toggle("TÃ¼rkÃ§e / English", value=(st.session_state.lang == 'EN')):
    st.session_state.lang = 'EN'
else:
    st.session_state.lang = 'TR'

LANG = LANG_OPTIONS[st.session_state.lang]
st.title(LANG['title'])

# Chat GeÃ§miÅŸi
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": LANG['intro']}]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

# Chat GiriÅŸi
if prompt := st.chat_input(LANG['input_hint']):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner(LANG['spinner']):
            response, sources = get_response(prompt)
            st.markdown(response)
            
            if sources:
                with st.expander(LANG['expander']):
                    for i, doc in enumerate(sources):
                        st.markdown(f"**Kaynak {i+1}:** {doc.metadata.get('source_dataset', 'Unknown')}")
                        st.code(doc.page_content[:300] + "...")
                        if i < len(sources)-1: st.divider()

    st.session_state.messages.append({"role": "assistant", "content": response})
